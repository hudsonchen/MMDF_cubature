{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zongchen/miniconda3/envs/mmd_cubature/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('/home/zongchen/mmd_flow_cubature/')\n",
    "sys.path.append('/home/zongchen/mmd_flow_cubature/')\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from mmd_flow.distributions import Distribution\n",
    "from mmd_flow.kernels import gaussian_kernel, laplace_kernel\n",
    "from mmd_flow.mmd import mmd_fixed_target\n",
    "from mmd_flow.gradient_flow import gradient_flow\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = 1.0\n",
    "kernel = gaussian_kernel(bandwidth)\n",
    "covariances = jnp.load('data/mog_covs.npy')\n",
    "means = jnp.load('data/mog_means.npy')\n",
    "# means = jnp.zeros((20, 2))\n",
    "# covariances = jnp.array([jnp.eye(2) for _ in range(20)])\n",
    "k = 20\n",
    "weights = jnp.ones(k) / k\n",
    "distribution = Distribution(kernel=kernel, means=means, covariances=covariances, integrand_name='neg_exp', weights=weights)\n",
    "mmd_func = mmd_fixed_target(None, kernel, distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05081233 0.04268435 0.05223575 0.05016228 0.04853699 0.05211426\n",
      " 0.04489118 0.05417713 0.05106026 0.04841987]\n",
      "[0.05046493 0.04264479 0.05197224 0.05010664 0.04831337 0.05190297\n",
      " 0.04474058 0.05393293 0.05089311 0.04820461]\n"
     ]
    }
   ],
   "source": [
    "rng_key = jax.random.PRNGKey(0)\n",
    "d = 10\n",
    "mean = jax.random.normal(rng_key, shape=(d, ))\n",
    "# mean = jnp.load('data/mog_means.npy')[0, :]\n",
    "\n",
    "rng_key, _ = jax.random.split(rng_key)\n",
    "A = jax.random.normal(rng_key, shape=(d, d))\n",
    "cov = jnp.dot(A, A.T) + d * jnp.eye(d)  # Ensures positive definiteness\n",
    "# cov = jnp.load('data/mog_covs.npy')[0, :, :]\n",
    "kernel = gaussian_kernel(5.0)\n",
    "rng_key, _ = jax.random.split(rng_key)\n",
    "Y = jax.random.normal(rng_key, shape=(10, d))\n",
    "\n",
    "closed_form_kme = kernel.mean_embedding(Y, mean, cov)\n",
    "print(closed_form_kme)\n",
    "rng_key, _ = jax.random.split(rng_key)\n",
    "samples = jax.random.multivariate_normal(rng_key, mean, cov, shape=[100000,]) \n",
    "gram_matrix = kernel.make_distance_matrix(Y, samples)\n",
    "print(gram_matrix.mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001892119908346623\n",
      "0.00019394465995004295\n"
     ]
    }
   ],
   "source": [
    "def kme_double_RBF_diff_Gaussian(mu_1, mu_2, Sigma_1, Sigma_2, l):\n",
    "    \"\"\"\n",
    "    Computes the double integral a gaussian kernel with lengthscale l, with two different Gaussians.\n",
    "    \n",
    "    Args:\n",
    "        mu_1, mu_2: (D,) \n",
    "        Sigma_1, Sigma_2: (D, D)\n",
    "        l : scalar\n",
    "\n",
    "    Returns:\n",
    "        A scalar: the value of the integral.\n",
    "    \"\"\"\n",
    "    D = mu_1.shape[0]\n",
    "    l_ = l ** 2\n",
    "    Lambda = jnp.eye(D) * l_\n",
    "    sum_ = Sigma_1 + Sigma_2 + Lambda\n",
    "    part_1 = jnp.sqrt(jnp.linalg.det(Lambda) / jnp.linalg.det(sum_))\n",
    "    sum_inv = jnp.linalg.inv(sum_)\n",
    "    # Compute exponent: - (1/2) * mu^T * (Σ1 + Σ2 + Lambda)⁻¹ * Γ⁻¹ * mu\n",
    "    exp_term = -0.5 * ((mu_1 - mu_2).T @ sum_inv @ (mu_1 - mu_2))\n",
    "    exp_value = jnp.exp(exp_term)\n",
    "    result = part_1 * exp_value\n",
    "    return result\n",
    "\n",
    "\n",
    "D = 3  # Dimension\n",
    "mu_1 = jnp.array([1.0, -0.5, 0.3])\n",
    "mu_2 = jnp.array([0.5, 0.2, -0.1])\n",
    "Sigma_1 = jnp.array([[1.0, 0.2, 0.1], [0.2, 1.5, 0.3], [0.1, 0.3, 2.0]])\n",
    "Sigma_2 = jnp.array([[1.2, 0.1, 0.0], [0.1, 1.3, 0.2], [0.0, 0.2, 1.1]])\n",
    "\n",
    "l = 0.1 # Kernel bandwidth\n",
    "sample_size = 1000  # Monte Carlo sample sizes\n",
    "# Compute closed-form solution\n",
    "closed_form_value = kme_double_RBF_diff_Gaussian(mu_1, mu_2, Sigma_1, Sigma_2, l)\n",
    "print(closed_form_value)\n",
    "rng_key = jax.random.PRNGKey(0)\n",
    "# Generate samples from N(mu, Sigma)\n",
    "L_1 = jnp.linalg.cholesky(Sigma_1)  # Cholesky decomposition\n",
    "L_2 = jnp.linalg.cholesky(Sigma_2)  # Cholesky decomposition\n",
    "rng_key, subkey = jax.random.split(rng_key)\n",
    "z_1 = jax.random.normal(rng_key, shape=(sample_size, D))  # Standard normal samples\n",
    "rng_key, subkey = jax.random.split(rng_key)\n",
    "z_2 = jax.random.normal(rng_key, shape=(sample_size, D))  # Standard normal samples\n",
    "samples_1 = mu_1 + z_1 @ L_1.T  # Transform to N(mu, Sigma)\n",
    "samples_2 = mu_2 + z_2 @ L_2.T  # Transform to N(mu, Sigma)\n",
    "kernel = gaussian_kernel(l)\n",
    "K = kernel.make_distance_matrix(samples_1, samples_2)\n",
    "print(K.mean())  # Monte Carlo mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.special import erf, erfc\n",
    "from jax.scipy.stats import norm\n",
    "\n",
    "@jax.jit\n",
    "def kme_Matern_12_Gaussian_1d(l, y):\n",
    "    \"\"\"\n",
    "    The implementation of the kernel mean embedding of the Matern one half kernel with Gaussian distribution\n",
    "    Only in one dimension, and the Gaussian distribution is N(0, 1)\n",
    "    \n",
    "    Args:\n",
    "        y: (M, )\n",
    "        l: scalar\n",
    "\n",
    "    Returns:\n",
    "        kernel mean embedding: (M, )\n",
    "    \"\"\"\n",
    "    # part1 = jnp.exp((1 - 2 * l * y) / (2 * l ** 2)) * (1 + erf((-1 + l * y) / (jnp.sqrt(2) * l)))\n",
    "    # part2 = jnp.exp((1 + 2 * l * y) / (2 * l ** 2)) * erfc((1 / l + y) / jnp.sqrt(2))\n",
    "\n",
    "    # return (part1 + part2) / 2\n",
    "    term1 = jnp.exp((1 + 2 * l * (y)) / (2 * l**2)) * norm.cdf((- 1 / l - y))\n",
    "    term2 = jnp.exp((1 - 2 * l * (y)) / (2 * l**2)) * norm.cdf((y - 1 / l))\n",
    "    return term1 + term2\n",
    "\n",
    "@jax.jit\n",
    "def kme_Matern_12_Gaussian(l, y):\n",
    "    \"\"\"\n",
    "    The implementation of the kernel mean embedding of the Matern one half kernel with Gaussian distribution\n",
    "    Only in one dimension, and the Gaussian distribution is N(0, 1)\n",
    "    \n",
    "    Args:\n",
    "        y: (M, D)\n",
    "        l: (D, )\n",
    "\n",
    "    Returns:\n",
    "        kernel mean embedding: (M, )\n",
    "    \"\"\"\n",
    "    high_d_map = jax.vmap(kme_Matern_12_Gaussian_1d, in_axes=(0, 0))\n",
    "    kme_all_d = high_d_map(l, y.T)\n",
    "    return jnp.prod(kme_all_d, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00338191 0.0054154 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04838518 0.06989565]\n",
      "[0.06989565 0.07747836]\n",
      "[0.00340957 0.00531105]\n",
      "[0.04870412 0.06914738]\n",
      "[0.06971382 0.07698251]\n"
     ]
    }
   ],
   "source": [
    "D = 2  # Dimension\n",
    "# mu_1 = jnp.array([1.0, -0.5, 0.3])\n",
    "# mu_2 = jnp.array([0.5, 0.2, -0.1])\n",
    "# Sigma_1 = jnp.array([[1.0, 0.2, 0.1], [0.2, 1.5, 0.3], [0.1, 0.3, 2.0]])\n",
    "# Sigma_2 = jnp.array([[1.2, 0.1, 0.0], [0.1, 1.3, 0.2], [0.0, 0.2, 1.1]])\n",
    "mu = jnp.zeros(D)\n",
    "Sigma = jnp.eye(D)\n",
    "y = jnp.array([[1.0, -0.5], [0.5, 0.2]])\n",
    "l = 0.1 # Kernel bandwidth\n",
    "sample_size = 100000  # Monte Carlo sample sizes\n",
    "# Compute closed-form solution\n",
    "closed_form_value = kme_Matern_12_Gaussian(l * jnp.ones(D), y)\n",
    "print(closed_form_value)\n",
    "closed_form_value_1 = kme_Matern_12_Gaussian(l * jnp.ones(1), y[:, 0][:, None])\n",
    "print(closed_form_value_1)\n",
    "closed_form_value_2 = kme_Matern_12_Gaussian(l * jnp.ones(1), y[:, 1][:, None])\n",
    "print(closed_form_value_2)\n",
    "\n",
    "\n",
    "rng_key = jax.random.PRNGKey(0)\n",
    "# Generate samples from N(mu, Sigma)\n",
    "L = jnp.linalg.cholesky(Sigma)  # Cholesky decomposition\n",
    "rng_key, subkey = jax.random.split(rng_key)\n",
    "z = jax.random.normal(rng_key, shape=(sample_size, D))  # Standard normal samples\n",
    "samples = mu + z @ L.T  # Transform to N(mu, Sigma)\n",
    "kernel = laplace_kernel(l)\n",
    "K = kernel.make_distance_matrix(samples, y)\n",
    "print(K.mean(0))  # Monte Carlo mean\n",
    "\n",
    "K1 = kernel.make_distance_matrix(samples[:, 0][:, None], y[:, 0][:, None])\n",
    "print(K1.mean(0))  # Monte Carlo mean\n",
    "\n",
    "K2 = kernel.make_distance_matrix(samples[:, 1][:, None], y[:, 1][:, None])\n",
    "print(K2.mean(0))  # Monte Carlo mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.00338191, 0.0054154 ], dtype=float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed_form_value_1 * closed_form_value_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04838518 0.06989565]\n",
      "[0.04870412 0.06914738]\n",
      "[0.04903114 0.06921551]\n"
     ]
    }
   ],
   "source": [
    "print(kme_Matern_12_Gaussian_1d(l, y[:, 0]))\n",
    "K1 = kernel.make_distance_matrix(samples[:, 0][:, None], y[:, 0][:, None])\n",
    "print(K1.mean(0)) \n",
    "\n",
    "samples = jax.random.normal(rng_key, shape=(sample_size, 1)) \n",
    "K1 = kernel.make_distance_matrix(samples, y[:, 0][:, None])\n",
    "print(K1.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52315658 0.51769674]\n",
      "[0.52215263 0.51703836]\n"
     ]
    }
   ],
   "source": [
    "y = jnp.array([[0.0, 0.2]]).T\n",
    "l = 1.0 # Kernel bandwidth\n",
    "sample_size = 100000  # Monte Carlo sample sizes\n",
    "# Compute closed-form solution\n",
    "closed_form_value = kme_Matern_12_Gaussian_1d(l, y[:, 0])\n",
    "print(closed_form_value)\n",
    "\n",
    "z = jax.random.normal(rng_key, shape=(sample_size, 1))  # Standard normal samples\n",
    "kernel = laplace_kernel(l)\n",
    "K = kernel.make_distance_matrix(z, y)\n",
    "print(K.mean(0))  # Monte Carlo mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52215263 0.51703836]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "dists = cdist(z, y, metric='cityblock')  # |x - y| for Laplace kernel\n",
    "kernel_vals = np.exp(-dists / l)\n",
    "print(kernel_vals.mean(0))  # Monte Carlo mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmd_cubature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
